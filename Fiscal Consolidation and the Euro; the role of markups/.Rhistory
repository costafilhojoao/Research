i=j=1
contribution[[i]][,j]
for ( i in 1:length( countries ) ) {
for (j in 1:nrow(contribution_sum)) {
contribution_sum[j,2] <- round( mean( contribution[[i]][,j] ), 2)
contribution_sum[j,3] <- round( sd( contribution[[i]][,j] ), 2 )
}
contribution_total[[i]] <- contribution_sum
}
names( contribution_total ) <- countries_names
rm(i, j)
contribution_total["Portugal"]
kable(contribution_total[["Portugal"]],
format = "latex",
booktabs = TRUE)
contribution_crisis <- list()
contribution_crisis <- list()
for ( i in 1:length( countries ) ) {
for (j in 1:nrow(contribution_sum)) {
contribution_sum[j,2] <- round( mean( contribution[[i]][63:73,j] ), 2)
contribution_sum[j,3] <- round( sd( contribution[[i]][63:73,j] ), 2 )
}
contribution_crisis[[i]] <- contribution_sum
}
names( contribution_crisis ) <- countries_names
rm(i, j, contribution_sum)
kable(contribution_crisis[["Portugal"]],
format = "latex",
booktabs = TRUE)
setwd("C:/Users/jcfil/Google Drive/Documents/Docência/ISEG/2020-2021 - MUFFINs/Materials share/Empirics/Markups")
lrate <- read_xlsx("Quarterly data/DataOECD.xlsx",
sheet = "OECD.Stat export",
range = "D8:D107",
col_names = FALSE)
srate <- read_xlsx("Quarterly data/DataOECD.xlsx",
sheet = "OECD.Stat export",
range = "E8:E107", col_names = FALSE)
spread = lrate - srate
spread = ts(spread, start = c(1995,1), frequency = 4)
markups_europe
View(markups_europe)
markups_europe[,15]
View(markups_europe)
data   <- data.frame(dates, mu = markups_europe[,15], spread)
View(data)
data   <- data.frame(dates, mu = markups_europe[,15], spread=spread)
View(data)
colnames(data) <- c("dates", "mu", "spread")
setwd("C:/Users/jcfil/Google Drive/Documents/Docência/ISEG/2020-2021 - MUFFINs/Materials share/Manuscript/Figures/Spread/Dispersions")
i=1
ggplot(data) + geom_line(aes(x = dates, y = spread), size = 0.8) +
theme_bw() + theme(text = element_text(size=24) ) +
geom_rect(data=recessions, aes(xmin=Peak,
xmax=Trough,
ymin=-Inf,
ymax=+Inf),
fill='gray', alpha=0.2) +
labs(x = "", y = "%")
data   <- data.frame(dates, mu = markups_europe[,15], spread)
colnames(data) <- c("dates", "mu", "spread")
setwd("C:/Users/jcfil/Google Drive/Documents/Docência/ISEG/2020-2021 - MUFFINs/Materials share/Manuscript/Figures/Spread/Dispersions")
ggplot(data) + geom_line(aes(x = dates, y = spread), size = 0.8) +
theme_bw() + theme(text = element_text(size=24) ) +
geom_rect(data=recessions, aes(xmin=Peak,
xmax=Trough,
ymin=-Inf,
ymax=+Inf),
fill='gray', alpha=0.2) +
labs(x = "", y = "%")
setwd("C:/Users/jcfil/Google Drive/Documents/Docência/ISEG/2020-2021 - MUFFINs/Materials share/Empirics/Markups")
primary <- read_xlsx("Annual data/DataOECD.xlsx",
sheet = "OECD.Stat export",
range = "C8:C32", col_names = FALSE)
colnames(primary) <- "primary"
primary <- ts(primary, start = syear, end = eyear, frequency = 1)
primary <- td(primary ~ 1, to = "quarterly", method = "denton-cholette")
primary <- predict(primary)
debt <- read_xlsx("Annual data/DataOECD.xlsx",
sheet = "OECD.Stat export",
range = "D8:D32", col_names = FALSE)
colnames(debt) <- "debt"
debt <- ts(debt, start = syear, end = eyear, frequency = 1)
debt <- td(debt ~ 1, to = "quarterly", method = "denton-cholette")
debt <- predict(debt)
unique(dat$na_item)
countries
VA <- subset( dat,  geo == "PT" & na_item == "B1G" & unit == "CP_MEUR" )
View(VA)
VA <- VA[ order( VA$time ), ]
View(VA)
VA <- matrix( data = NA,
nrow = eyear-syear+1,
ncol = nrow(sectors) )
data <- subset( dat,  geo == "PT" & na_item == "B1G" & unit == "CP_MEUR" )
data <- data[ order( data$time ), ]
VA <- matrix( data = NA,
nrow = eyear-syear+1,
ncol = nrow(sectors) )
rm(VA)
VA <- matrix( data = NA,
nrow = eyear-syear+1,
ncol = nrow(sectors) )
eyear-syear+1
VA <- matrix( data = NA,
nrow = eyear-syear+1,
ncol = length( sectors ) )
colnames( VA ) <- sectors
View(VA)
j=1
base <- subset( data, nace_r2 == nace[ j ] )
View(base)
base <- base[ 1:nrow( VA ), ]
View(base)
VA[ , j ] <- base$values
View(VA)
for (j in 1:ncol( VA ) ){
base <- subset( data, nace_r2 == nace[ j ] )
base <- base[ 1:nrow( VA ), ]
VA[ , j ] <- base$values
}
rm(j, base)
VA <- ts(VA, start = syear, end = eyear, frequency = 1)
VA_q <- matrix( data = NA,
nrow = ( eyear-syear +1) * 4,
ncol = length( sectors ) )
colnames( VA_q ) <- sectors
for (j in 1:ncol(VA) ){
m1 <- td(VA[,j] ~ 1, to = "quarterly", method = "denton-cholette")
VA_q[,j] <- predict(m1)
}
rm(j, m1)
VA_growth <- Va_q
VA_growth <- VA_q
View(VA_growth)
time                 <- c(1:length(mu))
time2                <- time^2
time                 <- c(1:nrows( VA_growth) )
time2                <- time^2
time                 <- c(1:nrow( VA_growth ) )
time2                <- time^2
for (j in 1:ncol( VA_growth ) ) {
VA_s   <- VA_q[,j]
reg    <- lm( log( VA_s ) ~ time + time2 )
beta0  <- reg[["coefficients"]][["(Intercept)"]]
beta1  <- reg[["coefficients"]][["time"]]
beta2  <- reg[["coefficients"]][["time2"]]
trend  <- ts(beta0 + beta1 * time + beta2 * time2,
start=c(1995,1), frequency = 4)
cycle                <- ( log( VA_s )-trend ) * 100
VA_growth[,j] <- cycle
}
rm(reg, beta0, beta1, beta2, trend, cycle, VA_s)
rm(j, reg, beta0, beta1, beta2, trend, cycle, VA_s)
rm(i)
hours <- read_xlsx("Quarterly data/DataOECD.xlsx",
sheet = "OECD.Stat export",
range = "C8:C107", col_names = FALSE)
colnames(hours) <- "hours"
hours <- ts(hours, start = c(1995,1), frequency = 4)
reg    <- lm( log( hours ) ~ time + time2 )
beta0  <- reg[["coefficients"]][["(Intercept)"]]
beta1  <- reg[["coefficients"]][["time"]]
beta2  <- reg[["coefficients"]][["time2"]]
trend  <- ts(beta0 + beta1 * time + beta2 * time2,
start=c(1995,1), frequency = 4)
hours_growth    <- ( log( hours ) - trend ) * 100
reg    <- lm( spread ~ time + time2 )
beta0  <- reg[["coefficients"]][["(Intercept)"]]
beta1  <- reg[["coefficients"]][["time"]]
beta2  <- reg[["coefficients"]][["time2"]]
trend  <- ts(beta0 + beta1 * time + beta2 * time2,
start=c(1995,1), frequency = 4)
spread_growth    <- spread - trend
reg    <- lm( primary ~ time + time2 )
beta0  <- reg[["coefficients"]][["(Intercept)"]]
beta1  <- reg[["coefficients"]][["time"]]
beta2  <- reg[["coefficients"]][["time2"]]
trend  <- ts(beta0 + beta1 * time + beta2 * time2,
start=c(1995,1), frequency = 4)
primary_growth    <- spread - trend
reg    <- lm( debt ~ time + time2 )
beta0  <- reg[["coefficients"]][["(Intercept)"]]
beta1  <- reg[["coefficients"]][["time"]]
beta2  <- reg[["coefficients"]][["time2"]]
trend  <- ts(beta0 + beta1 * time + beta2 * time2,
start=c(1995,1), frequency = 4)
debt_growth    <- debt - trend
data_econometrics <- data.frame(primary,
debt_growth,
spread_growth,
hours_growth,
markups_growth,
VA_growth
)
colnames(data_econometrics ) <- c( "primary",
"debt",
"spread",
"hours",
colnames(markups_growth),
colnames(VA_growth)
)
rm(data_econometrics)
lbvar <- data.frame(primary,
debt_growth,
spread_growth,
hours_growth,
markups_growth,
VA_growth
)
View(lbvar)
colnames( lbvar ) <- c( "primary",
"debt",
"spread",
"hours",
sectors,
sectors
)
View(lbvar)
setwd("C:/Users/jcfil/Google Drive/Documents/Papers/Acadêmicos/Research/Fiscal Consolidation and the Euro; the role of markups")
save.image("C:/Users/jcfil/Google Drive/Documents/Papers/Acadêmicos/Research/Fiscal Consolidation and the Euro; the role of markups/markupsdata.RData")
setwd("C:/Users/jcfil/Google Drive/Documents/Papers/Acadêmicos/Research/Fiscal Consolidation and the Euro; the role of markups")
library(nicethings)
library(HDeconometrics)
#load
nice_load(file = "markupsdata.RData", object = "lbvar", rename = NULL)
setwd("C:/Users/jcfil/Google Drive/Documents/Papers/Acadêmicos/Research/Fiscal Consolidation and the Euro; the role of markups")
library(haven)
library(plm)
library(nicethings)
library(knitr)
library(kableExtra)
library(stargazer)
library(latex2exp)
#load annual markups variation for selected European countries in Alesina et al. (2015) dataset
nice_load(file = "markupsdata.RData", object = "austerity", rename = NULL)
alesina         <- read_dta(file = "alesina.dta")
alesina         <- subset(alesina, year > 2007 & country != "GBR" )
countries_names <- c( rep("Austria", 7),
rep("Belgium", 7),
rep("Germany", 7),
rep("Denmark", 7),
rep("Spain", 7),
rep("Finland", 7),
rep("France", 7),
rep("Ireland", 7),
rep("Italy", 7),
rep("Portugal", 7),
rep("Sweden", 7))
alesina$country <- countries_names; rm( countries_names )
alesina$country <- factor( alesina$country )
#alphabetic order
alesina   <- alesina[ order( alesina$country ), ]
#regression dataset
data <- data.frame( country   = alesina$country,
year      = alesina$year,
dlngdp    = alesina$dlgdp * 100,
f_u_t     = alesina$f_u_t * 100,
f_a_t     = alesina$f_a_t * 100,
gini      = alesina$gini,
markup    = austerity$markup * 100,
markup_t1 = austerity$markup_t1 * 100,
markup2   = (austerity$markup * 100 )^2,
eb = alesina$eb,
tb = alesina$tb
)
rm( alesina, austerity )
#load annual markups variation for selected European countries in Alesina et al. (2015) dataset
nice_load(file = "markupsdata.RData", object = "austerity", rename = NULL)
alesina         <- read_dta(file = "alesina.dta")
alesina         <- subset(alesina, year > 2007 & country != "GBR" )
countries_names <- c( rep("Austria", 7),
rep("Belgium", 7),
rep("Germany", 7),
rep("Denmark", 7),
rep("Spain", 7),
rep("Finland", 7),
rep("France", 7),
rep("Ireland", 7),
rep("Italy", 7),
rep("Portugal", 7),
rep("Sweden", 7))
alesina$country <- countries_names; rm( countries_names )
alesina$country <- factor( alesina$country )
#alphabetic order
alesina   <- alesina[ order( alesina$country ), ]
View(austerity)
#regression dataset
data <- data.frame( country   = alesina$country,
year      = alesina$year,
dlngdp    = alesina$dlgdp * 100,
f_u_t     = alesina$f_u_t * 100,
f_a_t     = alesina$f_a_t * 100,
gini      = alesina$gini,
markup    = austerity$markup * 100,
markup_t1 = austerity$markup_t1 * 100,
markup2   = (austerity$markup * 100 )^2,
eb = alesina$eb,
tb = alesina$tb
)
alesina$country
load("markupsdata.RData")
attach( data.frame( markups_europe ) )
austerity <- data.frame( Austria, Belgium, Denmark, Germany,
Finland, France, Ireland, Italy,
Portugal, Spain, Sweden)
detach( data.frame( markups_europe ) )
austerity <- ts( austerity, start = c( syear, 1 ) , frequency = 4 )
#calculate 4-quarters accumulated aggregate markup change by country
austerity <- log( ( austerity + lag( austerity, 1 ) + lag( austerity, 2 ) + lag( austerity, 3 ) ) / 4 ) -
log( ( lag( austerity, 4 ) + lag( austerity, 5 ) + lag( austerity, 6 ) + lag( austerity, 7 ) ) / 4 )
colnames( austerity ) <- c( "Austria", "Belgium", "Denmark", "Germany",
"Finland", "France", "Ireland", "Italy",
"Portugal", "Spain", "Sweden")
#select the 4th quarter of each year to build annual (calendar-based) markup variation
austerity_t <- subset( austerity,
time( austerity ) == 2008.75 | time( austerity ) == 2009.75 |
time( austerity ) == 2010.75 | time( austerity ) == 2011.75 |
time( austerity ) == 2012.75 | time( austerity ) == 2013.75 |
time( austerity ) == 2014.75 )
View(austerity)
View(austerity_t)
#transform into panel data format
austerity_t <- t( austerity_t )
austerity_t <- data.frame( country = rownames( austerity_t ), austerity_t  )
View(austerity_t)
colnames( austerity_t ) <- c("country", seq( 2008, 2014 ) )
rownames( austerity_t ) <- NULL
austerity_t <- melt( austerity_t, id.vars = "country")
colnames( austerity_t ) = c("country", "year", "markup")
austerity_t <- austerity_t[ with( austerity_t, order(country, year)), ]
#select the lagged (t-1) 4th quarter of each year to build annual (calendar-based) markup variation
austerity_t1 <- subset( austerity,
time( austerity ) == 2007.75 | time( austerity ) == 2008.75 |
time( austerity ) == 2009.75 | time( austerity ) == 2010.75 |
time( austerity ) == 2011.75 | time( austerity ) == 2012.75 |
time( austerity ) == 2013.75 )
#transform into panel data format
austerity_t1 <- t( austerity_t1 )
austerity_t1 <- data.frame( country = rownames( austerity_t1 ), austerity_t1  )
colnames( austerity_t1 ) <- c("country", seq( 2008, 2014 ) )
rownames( austerity_t1 ) <- NULL
austerity_t1 <- melt( austerity_t1, id.vars = "country")
colnames( austerity_t1 ) = c("country", "year", "markup")
austerity_t1 <- austerity_t1[ with( austerity_t1, order(country, year)), ]
austerity <- data.frame( austerity_t, austerity_t1$markup  )
colnames(austerity) <- c("country", "year", "markup", "markup_t1")
rm( austerity_t, austerity_t1 )
save.image("C:/Users/jcfil/Google Drive/Documents/Papers/Acadêmicos/Research/Fiscal Consolidation and the Euro; the role of markups/markupsdata.RData")
setwd("C:/Users/jcfil/Google Drive/Documents/Papers/Acadêmicos/Research/Fiscal Consolidation and the Euro; the role of markups")
library(haven)
library(plm)
library(nicethings)
library(knitr)
library(kableExtra)
library(stargazer)
library(latex2exp)
#load annual markups variation for selected European countries in Alesina et al. (2015) dataset
nice_load(file = "markupsdata.RData", object = "austerity", rename = NULL)
alesina         <- read_dta(file = "alesina.dta")
alesina         <- subset(alesina, year > 2007 & country != "GBR" )
countries_names <- c( rep("Austria", 7),
rep("Belgium", 7),
rep("Germany", 7),
rep("Denmark", 7),
rep("Spain", 7),
rep("Finland", 7),
rep("France", 7),
rep("Ireland", 7),
rep("Italy", 7),
rep("Portugal", 7),
rep("Sweden", 7))
alesina$country <- countries_names; rm( countries_names )
alesina$country <- factor( alesina$country )
#alphabetic order
alesina   <- alesina[ order( alesina$country ), ]
#regression dataset
data <- data.frame( country   = alesina$country,
year      = alesina$year,
dlngdp    = alesina$dlgdp * 100,
f_u_t     = alesina$f_u_t * 100,
f_a_t     = alesina$f_a_t * 100,
gini      = alesina$gini,
markup    = austerity$markup * 100,
markup_t1 = austerity$markup_t1 * 100,
markup2   = (austerity$markup * 100 )^2,
eb = alesina$eb,
tb = alesina$tb
)
rm( alesina, austerity )
#### FGLS panel estimation ####
panel1 <- pggls( dlngdp ~ f_u_t + f_a_t,
data  = data,
index = c( "country", "year" ),
model = "pooling",
effect = "individual")
summary( panel1 )
panel2 <- pggls( dlngdp ~ f_u_t + f_a_t + gini,
data  = data,
index = c( "country", "year" ),
model = "pooling",
effect = "individual")
summary( panel2 )
panel3 <- pggls( dlngdp ~ f_u_t + f_a_t + gini + markup_t1,
data  = data,
index = c( "country", "year" ),
model = "pooling",
effect = "individual")
summary( panel3 )
panel4 <- pggls( dlngdp ~ f_u_t + f_a_t + gini + markup_t1 + gini * markup_t1,
data  = data,
index = c( "country", "year" ),
model = "pooling",
effect = "individual")
summary( panel4 )
summary( panel4 , digits = 2)
?ssummary
?summary
summary( panel4, digits )
summary( panel4, digits=2 )
type(panel4)
class(panel4)
size(data)
type(panel4)
class(panel4)
?summary.pggls
summary.pggls( panel4, digits=2 )
?summary.pggls
summary( panel4, digits=2 )
round(summary( panel4, digits=2 ),2)
summary( round(panel4, 2) )
extract.pggls <- function (model, include.rsquared = TRUE, include.adjrs = TRUE,
include.nobs = TRUE, ...)
{
s <- summary(model, ...)
coefficient.names <- rownames(s$CoefTable)
coefficients <- s$CoefTable[, 1]
standard.errors <- s$CoefTable[, 2]
significance <- s$CoefTable[, 4]
rs <- s$rsqr
n <- length(s$resid)
gof <- numeric()
gof.names <- character()
gof.decimal <- logical()
if (include.rsquared == TRUE) {
gof <- c(gof, rs)
gof.names <- c(gof.names, "R$^2$")
gof.decimal <- c(gof.decimal, TRUE)
}
if (include.nobs == TRUE) {
gof <- c(gof, n)
gof.names <- c(gof.names, "Num. obs.")
gof.decimal <- c(gof.decimal, FALSE)
}
tr <- createTexreg(coef.names = coefficient.names, coef = coefficients,
se = standard.errors, pvalues = significance, gof.names = gof.names,
gof = gof, gof.decimal = gof.decimal)
return(tr)
}
setMethod("extract", signature = className("pggls", "plm"),
definition = extract.pggls)
?setMethod
setMethod("extract", signature = className("pggls", "plm"),
definition = extract.pggls)
setMethod("extract",
signature = className("pggls", "plm"),
definition = extract.pggls)
rm(extract.pggls())
rm(extract.pggls
)
?stargazer
stargazer(panel4)
summary( plm( dlngdp ~ f_u_t + f_a_t + gini + markup_t1 + gini * markup_t1,
data  = data,
index = c( "country", "year" ),
model = "fixed",
effect = "twoways") )
summary( plm( dlngdp ~ f_u_t + f_a_t + gini + markup_t1 + gini * markup_t1,
data  = data,
index = c( "country", "year" ),
model = "within",
effect = "twoways") )
summary( plm( dlngdp ~ f_u_t + f_a_t + gini + markup_t1,
data  = data,
index = c( "country", "year" ),
model = "within",
effect = "twoways") )
save.image("C:/Users/jcfil/Google Drive/Documents/Papers/Acadêmicos/Research/Fiscal Consolidation and the Euro; the role of markups/paneldata.RData")
summary( panel1 )
summary( panel2 )
summary( panel3 )
summary( panel4 )
save.image("C:/Users/jcfil/Google Drive/Documents/Papers/Acadêmicos/Research/Fiscal Consolidation and the Euro; the role of markups/panel.R.RData")
setwd("C:/Users/jcfil/Google Drive/Documents/Papers/Acadêmicos/Research/Fiscal Consolidation and the Euro; the role of markups")
library(nicethings)
library(HDeconometrics)
#load
nice_load(file = "markupsdata.RData", object = "lbvar", rename = NULL)
View(lbvar)
View(lbvar)
modelbvar <- lbvar(lbvar,
p = 4,
delta = 0.5,
lambda = 0.05)
ident     <- identification( modelbvar )
responses <- irf(modelbvar,
ident,
h = 12,
boot = TRUE,
M = 1000,
unity.shock = TRUE)
irf_list = list()
save.image("C:/Users/jcfil/Google Drive/Documents/Papers/Acadêmicos/Research/Fiscal Consolidation and the Euro; the role of markups/lbvardara.RData")
